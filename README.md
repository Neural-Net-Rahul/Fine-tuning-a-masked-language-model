# P3-Fine-tuning-a-masked-language-model
This repository houses a fine-tuned masked language model based on the DistilBERT architecture. The model has been specifically fine-tuned on the IMDb dataset. The objective of the fine-tuning process is to enhance the model's ability to predict masked tokens within the input sequences nuances present in IMDb reviews.
